{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 10 # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 1000 # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 100  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 20  # @param {type:\"integer\"}\n",
    "eval_interval = 500  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\"\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (96, 48)\n",
    "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2,\n",
    "    single_deterministic_pass=False).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 100: loss = 18.878053665161133\n",
      "step = 200: loss = 1.24805748462677\n",
      "step = 300: loss = 2.0433998107910156\n",
      "step = 400: loss = 7.261974334716797\n",
      "step = 500: loss = 3.788455009460449\n",
      "step = 500: Average Return = 59.150001525878906\n",
      "step = 600: loss = 64.98619842529297\n",
      "step = 700: loss = 26.495784759521484\n",
      "step = 800: loss = 20.360095977783203\n",
      "step = 900: loss = 61.84721374511719\n",
      "step = 1000: loss = 594.809814453125\n",
      "step = 1000: Average Return = 87.44999694824219\n",
      "step = 1100: loss = 702.18603515625\n",
      "step = 1200: loss = 9.30987548828125\n",
      "step = 1300: loss = 22.97235870361328\n",
      "step = 1400: loss = 648.2876586914062\n",
      "step = 1500: loss = 26.476051330566406\n",
      "step = 1500: Average Return = 80.0999984741211\n",
      "step = 1600: loss = 1321.3763427734375\n",
      "step = 1700: loss = 289.4484558105469\n",
      "step = 1800: loss = 12.957220077514648\n",
      "step = 1900: loss = 441.9720764160156\n",
      "step = 2000: loss = 307.5409851074219\n",
      "step = 2000: Average Return = 106.75\n",
      "step = 2100: loss = 64.6771011352539\n",
      "step = 2200: loss = 12.557291030883789\n",
      "step = 2300: loss = 10.076436042785645\n",
      "step = 2400: loss = 3.808570623397827\n",
      "step = 2500: loss = 5.633056163787842\n",
      "step = 2500: Average Return = 132.85000610351562\n",
      "step = 2600: loss = 6.428610801696777\n",
      "step = 2700: loss = 3.8552186489105225\n",
      "step = 2800: loss = 5.360207557678223\n",
      "step = 2900: loss = 3.553541421890259\n",
      "step = 3000: loss = 4.810835361480713\n",
      "step = 3000: Average Return = 148.39999389648438\n",
      "step = 3100: loss = 2.200248956680298\n",
      "step = 3200: loss = 1.9857957363128662\n",
      "step = 3300: loss = 8.784151077270508\n",
      "step = 3400: loss = 1.5050666332244873\n",
      "step = 3500: loss = 0.5941607356071472\n",
      "step = 3500: Average Return = 176.0\n",
      "step = 3600: loss = 10.035301208496094\n",
      "step = 3700: loss = 2.5916221141815186\n",
      "step = 3800: loss = 1.2067252397537231\n",
      "step = 3900: loss = 1.0857281684875488\n",
      "step = 4000: loss = 5.209518909454346\n",
      "step = 4000: Average Return = 196.85000610351562\n",
      "step = 4100: loss = 1.6218082904815674\n",
      "step = 4200: loss = 3.2856156826019287\n",
      "step = 4300: loss = 301.52276611328125\n",
      "step = 4400: loss = 11.935209274291992\n",
      "step = 4500: loss = 12.052887916564941\n",
      "step = 4500: Average Return = 200.0\n",
      "step = 4600: loss = 269.53680419921875\n",
      "step = 4700: loss = 2.5330491065979004\n",
      "step = 4800: loss = 46.3013916015625\n",
      "step = 4900: loss = 718.0831909179688\n",
      "step = 5000: loss = 38.367431640625\n",
      "step = 5000: Average Return = 167.6999969482422\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "  train_env,\n",
    "  agent.collect_policy,\n",
    "  observers=[replay_buffer.add_batch],\n",
    "  num_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.18249959945678818, 250.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, agent.policy, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = eval_env.reset()\n",
    "      video.append_data(eval_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = eval_env.step(action_step.action)\n",
    "        video.append_data(eval_py_env.render())\n",
    "  return Video(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x7fa5c8048000] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"trained-agent.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_policy_eval_video(agent.policy, \"trained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_policy_eval_video(policy, env, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = env.reset()\n",
    "      video.append_data(tf.squeeze(env.render()).numpy())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = env.step(action_step.action)\n",
    "        video.append_data(tf.squeeze(env.render()).numpy())\n",
    "  return Video(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_episodes(policy, env, py_env, num_episodes=5):\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = env.reset()\n",
    "      env.render(mode=\"human\")\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = env.step(action_step.action)\n",
    "        env.render(mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunar_py_env = suite_gym.load(\"LunarLander-v2\")\n",
    "lunar_env = tf_py_environment.TFPyEnvironment(lunar_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(8,), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunar_env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(lunar_env.time_step_spec(), lunar_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x7fb3c8008000] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"lunar-lander.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_policy_eval_video(random_policy, lunar_env, \"lunar-lander\", num_episodes=5, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49f76707e5413b80002d05f39c64eb054ab5c733abfce764de0913f5c1449f72"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('reinforcement-uN1m85U_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
